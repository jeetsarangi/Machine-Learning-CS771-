{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f17e0e",
   "metadata": {},
   "source": [
    "# Question 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c412735",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b8950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time as tim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f639cb",
   "metadata": {},
   "source": [
    "Below is the code given in the assignment for calculating gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d24952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(gradient,init_,learn_rate,n_iter=50,tol=1e-06):\n",
    "    x = init_\n",
    "    for _ in range(n_iter):\n",
    "        delta = -learn_rate*gradient(x)\n",
    "        if np.all(np.abs(delta) <= tol):\n",
    "            break\n",
    "        x += delta\n",
    "    return round(x*1000)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759601a",
   "metadata": {},
   "source": [
    "Now as per question 1,a I have shown below the functions for calculation the gradient for the polynomial function \n",
    "$ x^2 + 3x + 4 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b38ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def First(x):\n",
    "    return 2*x+3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30e8c8",
   "metadata": {},
   "source": [
    "Now to find the minima for the function we can use the gradient descent algorithm to reach the lower extremum we have set the initial value to be 0 and the learning rate here I have set a bit high that is 0.1 cause it works fine with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dd7ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minima for first one is at x=-1.5\n"
     ]
    }
   ],
   "source": [
    "minima1 = gradient_descent(gradient = First,init_ = 0,learn_rate = 0.1)\n",
    "print(\"The minima for first one is at x=\"+str(minima1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824f8bb",
   "metadata": {},
   "source": [
    "Now for the second polynomial function $ x^4 â€“ 3x^2 + 2x$ the gradient function is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02607564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second(x):\n",
    "    a = 4*(x**3)\n",
    "    b = 6*x\n",
    "    return a-b+2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362bbf8f",
   "metadata": {},
   "source": [
    "Now to find the minima for the function we can use the gradient descent algorithm to reach the lower extremum we have set the initial value to be 0 and the learning rate is 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7f4cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minima for Second one is at x =-1.357\n"
     ]
    }
   ],
   "source": [
    "minima2 = gradient_descent(gradient = second,init_ = 0,learn_rate = 0.01)\n",
    "print(\"The minima for Second one is at x =\"+str(minima2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba4f8e",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9205a0",
   "metadata": {},
   "source": [
    "Now to calculate the gradient for Loss function of the regression $y = ax+b$ we differentiate the loss function\n",
    "$\\frac{1}{N} * \\sum_{i=0}^N (y_i-y_{pred}^i) $ which uses the mean square error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459176af",
   "metadata": {},
   "source": [
    "After differentiation we found the gradient as a vector of partial derivatives once with respect to a and once with b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cae0d1",
   "metadata": {},
   "source": [
    "$D_a = \\frac{-2}{N}\\sum_{i=0}^N (y_i-y_{pred}^i)x_n $ \n",
    "$D_b = \\frac{-2}{N}\\sum_{i=0}^N (y_i-y_{pred}^i) $ \n",
    "Below function used the above and return gradients given X,Y,a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cbfe778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X,Y,a,b):\n",
    "    n = len(X)\n",
    "    Y_pred = a*X+b\n",
    "    D_a = (-2/n) * np.dot(X,(Y - Y_pred))\n",
    "    D_b = (-2/n) * sum(Y - Y_pred)\n",
    "    return D_a,D_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0756218",
   "metadata": {},
   "source": [
    "The below function is same as above gradient descent function just it takes arguments of X,Y also with the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa47b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mygradient_descent(gradient,X,Y,init_a,init_b,learn_rate,n_iter=50,tol=1e-06):\n",
    "    a = init_a\n",
    "    b = init_b\n",
    "    for _ in range(n_iter):\n",
    "\n",
    "        d_a,d_b = gradient(X,Y,a,b)\n",
    "        delta_a,delta_b = -learn_rate*d_a,-learn_rate*d_b\n",
    "\n",
    "        if np.all(np.abs([delta_a,delta_b]) <= tol):\n",
    "                break\n",
    "\n",
    "        a += delta_a \n",
    "        b += delta_b\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8952688",
   "metadata": {},
   "source": [
    "## c)\n",
    "Below function is given in the question to generate random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0a7286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generaterandomdata():\n",
    "    np.random.seed(0)\n",
    "    X = 2.5*np.random.randn(10000)+1.5\n",
    "    res = 1.5*np.random.randn(10000)\n",
    "    y = 2+0.3*X+res\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99fb821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters a and b after being updated to minimise the Loss is a = 0.2953318623386959 b = 2.02321971821676\n"
     ]
    }
   ],
   "source": [
    "X,Y = generaterandomdata()\n",
    "res = mygradient_descent(gradient,X,Y,0,0,0.01,1000,1e-06)\n",
    "print(\"The parameters a and b after being updated to minimise the Loss is a = \"+str(res[0])+\" b = \"+str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aae0d1c",
   "metadata": {},
   "source": [
    "# d)\n",
    "Now,Lets implement Minibatch stochastic gradient descent there are two ways to implement this algorithm \n",
    "1.We take B indices randomly (let's say it is the batch size) i.e. data points, compute gradient using those and then update weights. And repeat this for N iterations as explained in the course slides.\n",
    "2.We shuffle the data, then iterate on the whole data in sets of 100 and update the weights after computing gradient for each set. And we repeat this for N iterations.\n",
    "I have implemented the First one below as per the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddfd672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatchsgd(gradient,X,Y,learn_rate,batch_size = 50,n_iter = 50,tol=1e-06):\n",
    "    n_obs = X.shape[0]\n",
    "    a = 0\n",
    "    b = 0\n",
    "    \n",
    "    for _ in range(n_iter):\n",
    "        \n",
    "        index = np.random.permutation(len(X))\n",
    "        X = X[index]\n",
    "        Y = Y[index]\n",
    "        \n",
    "        x_batch,y_batch = X[0:batch_size],Y[0:batch_size]\n",
    "        d_a,d_b = gradient(x_batch, y_batch,a,b)\n",
    "        delta_a,delta_b = -learn_rate*d_a,-learn_rate*d_b\n",
    "        \n",
    "        if np.all(np.abs([delta_a,delta_b]) <= tol):\n",
    "                break\n",
    "        \n",
    "        a += delta_a\n",
    "        b += delta_b\n",
    "        \n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08200742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For learning rate at 0.01 and batchsize as 100 and iteration as 500 minibatch sgd gives optimal values of a and b for linear \n",
      "regression y = ax+b Loss minimisation as a = 0.3159717425712388, b = 2.0363174620297104\n"
     ]
    }
   ],
   "source": [
    "X,Y = generaterandomdata()\n",
    "res = minibatchsgd(gradient,X,Y,learn_rate = 0.01,batch_size = 100,n_iter = 500)\n",
    "print(\"For learning rate at 0.01 and batchsize as 100 and iteration as 500 minibatch sgd gives optimal values of a and b for linear \\nregression y = ax+b Loss minimisation as a = \"+str(res[0])+\", b = \"+str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbff8f0",
   "metadata": {},
   "source": [
    "## e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2169f",
   "metadata": {},
   "source": [
    "Now for this question we'll first try for using minibatch sgd as sgd just by putting batchsize = 1,as per the course defination\n",
    "So,we dont need to implement new SGD algorithm we can reuse the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1313fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For learning rate at 0.01 and batchsize as 1 and iteration as 500 minibatch sgd gives optimal values of a and b for linear \n",
      "regression y = ax+b Loss minimisation as a = 0.03545573877167239 b = 1.9075919586872565\n"
     ]
    }
   ],
   "source": [
    "X,Y = generaterandomdata()\n",
    "res = minibatchsgd(gradient,X,Y,learn_rate = 0.01,batch_size = 1,n_iter = 500)\n",
    "print(\"For learning rate at 0.01 and batchsize as 1 and iteration as 500 minibatch sgd gives optimal values of a and b for linear \\nregression y = ax+b Loss minimisation as a = \"+str(res[0])+\" b = \"+str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ecad1",
   "metadata": {},
   "source": [
    "This was actually very fast for our data but as we can see above the accuracy is way too low.So,lets try the same algorithm with some more iteration as its faster it can do more iteration quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20fa6cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For learning rate at 0.01 and batchsize as 1 and iteration as 10000 minibatch sgd gives optimal values of a and b for linear \n",
      "regression y = ax+b Loss minimisation as a = 0.2874303279336194 b = 2.411947034850882\n"
     ]
    }
   ],
   "source": [
    "X,Y = generaterandomdata()\n",
    "res = minibatchsgd(gradient,X,Y,learn_rate = 0.01,batch_size = 1,n_iter = 10000)\n",
    "print(\"For learning rate at 0.01 and batchsize as 1 and iteration as 10000 minibatch sgd gives optimal values of a and b for linear \\nregression y = ax+b Loss minimisation as a = \"+str(res[0])+\" b = \"+str(res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d6ffb",
   "metadata": {},
   "source": [
    "So,now with these many iterations it algorithm became a bit slow although the accuracy increased but still less accurate than \n",
    "gradient descent and minibatch stochastic gradient descent.Hence can be used for larger dataset accuracy will get hit but the algorithm works quite faster than other two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccae50",
   "metadata": {},
   "source": [
    "Lets,now try to find an optimal Batchsize for Minibatch SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46ba47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = generaterandomdata()\n",
    "a = 0.3\n",
    "b = 2\n",
    "Error = []\n",
    "minimum = 10000\n",
    "minbatch = 1\n",
    "for batchsize in range(50,1000,25):\n",
    "    res = minibatchsgd(gradient,X,Y,learn_rate = 0.01,batch_size = batchsize,n_iter = 500)\n",
    "    mse = ((a-res[0])**2+(b-res[1])**2)/2\n",
    "    if minimum > mse:\n",
    "        minimum = mse\n",
    "        minbatch = batchsize\n",
    "    Error.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c880e945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1418b50f310>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batchsize = [i for i in range(50,1000,25)]\n",
    "plt.plot(batchsize,Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af17e4",
   "metadata": {},
   "source": [
    "#### Optimal Batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d03b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal Batchsize is = 550 For the given data Data\n"
     ]
    }
   ],
   "source": [
    "print(\"The optimal Batchsize is = \"+str(minbatch)+\" For the given data Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db07c4",
   "metadata": {},
   "source": [
    "Now lets compare the time taken by each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ecd1bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For gradient descent Time takin with learning rate 0.001 and iteration 10000 is 14.6875\n",
      "For minibatch stochastic gd Time takin with learning rate 0.001 and iteration 10000 is 9.859375\n",
      "For stochastic gd Time takin with learning rate 0.001 and iteration 10000 is 5.734375\n",
      "Improvement in terms of time from Gradient descent to Stochastic Gradient Descent is = 39.04255319148936%age\n"
     ]
    }
   ],
   "source": [
    "X,Y = generaterandomdata()\n",
    "tic = tim.process_time()\n",
    "res = mygradient_descent(gradient,X,Y,0,0,learn_rate = 0.001,n_iter = 10000)\n",
    "toc = tim.process_time()\n",
    "timeofgd = toc-tic\n",
    "print(\"For gradient descent Time takin with learning rate 0.001 and iteration 10000 is \"+str(toc-tic))\n",
    "tic = tim.process_time()\n",
    "res2 =  minibatchsgd(gradient,X,Y,learn_rate = 0.001,batch_size = 100,n_iter = 10000)\n",
    "toc = tim.process_time()\n",
    "print(\"For minibatch stochastic gd Time takin with learning rate 0.001 and iteration 10000 is \"+str(toc-tic))\n",
    "tic = tim.process_time()\n",
    "res3 =  minibatchsgd(gradient,X,Y,learn_rate = 0.001,batch_size = 1,n_iter = 10000)\n",
    "toc = tim.process_time()\n",
    "timeofsgd = toc-tic\n",
    "print(\"For stochastic gd Time takin with learning rate 0.001 and iteration 10000 is \"+str(toc-tic))\n",
    "print(\"Improvement in terms of time from Gradient descent to Stochastic Gradient Descent is = \"+str((timeofsgd/timeofgd)*100)+\"%age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdd6f6",
   "metadata": {},
   "source": [
    "From the above we can clearly see that for this data sgd is way more faster than other two and basically time for </br>Gradient descent > Minibatch Stochastic Gradient Descent > Stochastic Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a065d76",
   "metadata": {},
   "source": [
    "# Question no 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb511b9a",
   "metadata": {},
   "source": [
    "(i) The probability that someone has both cold and a fever\n",
    "    According to the given Bayesian Network the fever is dependent on cold.Hence,\n",
    "    $P(Fever,Cold) = P(Cold)*P(\\frac{Fever}{Cold}) = 0.02 * 0.307 = 0.00614$(Answer)</br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ca73c",
   "metadata": {},
   "source": [
    "(ii)The probability that someone who has a cough has a cold.\n",
    "</br></br>\n",
    "$\n",
    "P(\\frac{Cold}{Cough}) = \\frac{P(Cold,Cough)}{P(Cough)}\n",
    "$</br></br>\n",
    "Lets First calculate the probability of Lung Disease</br>\n",
    "$\n",
    "P(Lung) = P(Lung,Smoke)+P(Lung,NoSmoke) = (0.2*0.1009) + (0.8*0.001) = 0.02098$</br>$\n",
    "P(NoLung) = 1-P(Lung) = 0.97902\n",
    "$</br>\n",
    "</br>Now Lets Calculate Final result:</br>\n",
    "</br>$\n",
    "\\frac{P(Cold,Cough)}{P(Cough)} = \\frac{P(Cold,Cough)}{P(Cold,Cough)+P(Cold,NoCough)} = \\frac{(0.7575*0.02*0.02098)+(0.505*0.02*0.97902)}{(0.7575*0.02*0.02098)+(0.505*0.02*0.97902)+(0.505*0.98*0.02098)+(0.01+0.98+0.97902)}\n",
    "$</br></br>\n",
    "$\n",
    " = \\frac{0.000318+0.00989}{0.000318+0.00989+0.01038+0.00959} = 0.3382$(approx)(Answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab440354",
   "metadata": {},
   "source": [
    "## Question no 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ef581",
   "metadata": {},
   "source": [
    "The probability mass function is given as $$ f(X1,X2,....,Xk) = \\frac{n!}{x1!,x2!,...,xk!}P_1^ {x1}...P_k^ {xk}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7864b8",
   "metadata": {},
   "source": [
    "where $\\sum_{i=1}^{k} x_i = n$ and $\\sum_{i=1}^{k} P_i = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee926212",
   "metadata": {},
   "source": [
    "The likelihood could be then written as joint probability:$L(\\mathbf{p}) = {{n}\\choose{x_1, ..., x_m}}\\prod_{i=1}^m p_i^{x_i} \\\\\n",
    "= n! \\prod_{i=1}^m \\frac{p_i^{x_i}}{x_i!}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d76e4a",
   "metadata": {},
   "source": [
    "Then The log liklihood is : $l(\\mathbf{p}) = \\log L(\\mathbf{p}) = \\log \\bigg( n! \\prod_{i=1}^m \\frac{p_i^{x_i}}{x_i!} \\bigg)$</br>\n",
    "$= \\log n! + \\log \\prod_{i=1}^m \\frac{p_i^{x_i}}{x_i!}\\\\\n",
    "= \\log n! + \\sum_{i=1}^m \\log \\frac{p_i^{x_i}}{x_i!} \\\\\n",
    "= \\log n! + \\sum_{i=1}^m x_i \\log p_i - \\sum_{i=1}^m \\log x_i!\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75926c",
   "metadata": {},
   "source": [
    "After putting a constraint with Lagrange multiplier i.e $\\sum_{i=1}^m p_i = 1$</br>\n",
    "$l'(\\mathbf{p},\\lambda) = l(\\mathbf{p}) + \\lambda\\bigg(1 - \\sum_{i=1}^m p_i\\bigg)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084186a4",
   "metadata": {},
   "source": [
    "For finding the maximum p for $ L(\\mathbf{p},\\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fa40c",
   "metadata": {},
   "source": [
    "$\\frac{\\partial}{\\partial p_i} l'(\\mathbf{p},\\lambda)= \\frac{\\partial}{\\partial p_i} l(\\mathbf{p})\n",
    "+ \\frac{\\partial}{\\partial p_i} \\lambda\\bigg(1 - \\sum_{i=1}^m p_i\\bigg) = 0$\n",
    "</br>\n",
    "$ \\frac{\\partial}{\\partial p_i} \\sum_{i=1}^m x_i \\log p_i\n",
    "- \\lambda \\frac{\\partial}{\\partial p_i} \\sum_{i=1}^m p_i = 0 $</br>$ \n",
    "\\frac{x_i}{p_i}- \\lambda  = 0 $</br>$\n",
    "p_i = \\frac{x_i}{\\lambda} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305174b8",
   "metadata": {},
   "source": [
    "Thus,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea826cb",
   "metadata": {},
   "source": [
    "$p_i = \\frac{x_i}{n}$, because $p_i = \\frac{x_i}{\\lambda} $</br>\n",
    "$\\sum_{i=1}^m p_i = \\sum_{i=1}^m \\frac{x_i}{\\lambda} $</br>\n",
    "$1 = \\frac{1}{\\lambda} \\sum_{i=1}^m x_i $</br>\n",
    "$\\lambda = n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08e3976",
   "metadata": {},
   "source": [
    "distribution that maximizes the likelihood is :\n",
    "$\\mathbf{p} = (\\frac{x_1}{n},\n",
    "...,\n",
    "\\frac{x_m}{n})$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
